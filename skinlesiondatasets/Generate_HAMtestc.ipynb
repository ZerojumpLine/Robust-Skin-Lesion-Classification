{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-32263731/ipykernel_85535/25374647.py:22: DeprecationWarning: Please use `map_coordinates` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import map_coordinates\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import os.path\n",
    "import time\n",
    "import torch\n",
    "import tqdm\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as trn\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "import skimage as sk\n",
    "from skimage.filters import gaussian\n",
    "from io import BytesIO\n",
    "from wand.image import Image as WandImage\n",
    "from wand.api import library as wandlibrary\n",
    "import wand.color as WandColor\n",
    "import ctypes\n",
    "from PIL import Image as PILImage\n",
    "import cv2\n",
    "from scipy.ndimage import zoom as scizoom\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAMtestfolder = './SkinLesionDatasets/HAMtest/'\n",
    "HAMtestcpath = './SkinLesionDatasets_C/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# /////////////// Data Loader ///////////////\n",
    "\n",
    "\n",
    "IMG_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm']\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    \"\"\"Checks if a file is an image.\n",
    "    Args:\n",
    "        filename (string): path to a file\n",
    "    Returns:\n",
    "        bool: True if the filename ends with a known image extension\n",
    "    \"\"\"\n",
    "    filename_lower = filename.lower()\n",
    "    return any(filename_lower.endswith(ext) for ext in IMG_EXTENSIONS)\n",
    "\n",
    "\n",
    "def find_classes(dir):\n",
    "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "\n",
    "def make_dataset(dir, class_to_idx):\n",
    "    images = []\n",
    "    dir = os.path.expanduser(dir)\n",
    "    for target in sorted(os.listdir(dir)):\n",
    "        d = os.path.join(dir, target)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if is_image_file(fname):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    item = (path, class_to_idx[target])\n",
    "                    images.append(item)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "class DistortImageFolder(data.Dataset):\n",
    "    def __init__(self, root, method, severity, transform=None, target_transform=None,\n",
    "                 loader=default_loader):\n",
    "        classes, class_to_idx = find_classes(root)\n",
    "        imgs = make_dataset(root, class_to_idx)\n",
    "        if len(imgs) == 0:\n",
    "            raise (RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                                                                             \"Supported image extensions are: \" + \",\".join(\n",
    "                IMG_EXTENSIONS)))\n",
    "\n",
    "        self.root = root\n",
    "        self.method = method\n",
    "        self.severity = severity\n",
    "        self.imgs = imgs\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        \n",
    "        img = self.method(img, self.severity)\n",
    "        \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        save_path = HAMtestcpath + self.method.__name__ + \\\n",
    "                    '/' + str(self.severity) + '/' + self.idx_to_class[target]\n",
    "\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        save_path += path[path.rindex('/'):]\n",
    "\n",
    "        Image.fromarray(np.uint8(img)).save(save_path, quality=85, optimize=True)\n",
    "\n",
    "        return 0  # we do not care about returning the data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "# /////////////// Distortion Helpers ///////////////\n",
    "\n",
    "\n",
    "def auc(errs):  # area under the alteration error curve\n",
    "    area = 0\n",
    "    for i in range(1, len(errs)):\n",
    "        area += (errs[i] + errs[i - 1]) / 2\n",
    "    area /= len(errs) - 1\n",
    "    return area\n",
    "\n",
    "\n",
    "def disk(radius, alias_blur=0.1, dtype=np.float32):\n",
    "    if radius <= 8:\n",
    "        L = np.arange(-8, 8 + 1)\n",
    "        ksize = (3, 3)\n",
    "    else:\n",
    "        L = np.arange(-radius, radius + 1)\n",
    "        ksize = (5, 5)\n",
    "    X, Y = np.meshgrid(L, L)\n",
    "    aliased_disk = np.array((X ** 2 + Y ** 2) <= radius ** 2, dtype=dtype)\n",
    "    aliased_disk /= np.sum(aliased_disk)\n",
    "\n",
    "    # supersample disk to antialias\n",
    "    return cv2.GaussianBlur(aliased_disk, ksize=ksize, sigmaX=alias_blur)\n",
    "\n",
    "\n",
    "# Tell Python about the C method\n",
    "wandlibrary.MagickMotionBlurImage.argtypes = (ctypes.c_void_p,  # wand\n",
    "                                              ctypes.c_double,  # radius\n",
    "                                              ctypes.c_double,  # sigma\n",
    "                                              ctypes.c_double)  # angle\n",
    "\n",
    "\n",
    "# Extend wand.image.Image class to include method signature\n",
    "class MotionImage(WandImage):\n",
    "    def motion_blur(self, radius=0.0, sigma=0.0, angle=0.0):\n",
    "        wandlibrary.MagickMotionBlurImage(self.wand, radius, sigma, angle)\n",
    "\n",
    "\n",
    "# modification of https://github.com/FLHerne/mapgen/blob/master/diamondsquare.py\n",
    "def plasma_fractal(mapsize=256, wibbledecay=3):\n",
    "    \"\"\"\n",
    "    Generate a heightmap using diamond-square algorithm.\n",
    "    Return square 2d array, side length 'mapsize', of floats in range 0-255.\n",
    "    'mapsize' must be a power of two.\n",
    "    \"\"\"\n",
    "    assert (mapsize & (mapsize - 1) == 0)\n",
    "    maparray = np.empty((mapsize, mapsize), dtype=np.float_)\n",
    "    maparray[0, 0] = 0\n",
    "    stepsize = mapsize\n",
    "    wibble = 100\n",
    "\n",
    "    def wibbledmean(array):\n",
    "        return array / 4 + wibble * np.random.uniform(-wibble, wibble, array.shape)\n",
    "\n",
    "    def fillsquares():\n",
    "        \"\"\"For each square of points stepsize apart,\n",
    "           calculate middle value as mean of points + wibble\"\"\"\n",
    "        cornerref = maparray[0:mapsize:stepsize, 0:mapsize:stepsize]\n",
    "        squareaccum = cornerref + np.roll(cornerref, shift=-1, axis=0)\n",
    "        squareaccum += np.roll(squareaccum, shift=-1, axis=1)\n",
    "        maparray[stepsize // 2:mapsize:stepsize,\n",
    "        stepsize // 2:mapsize:stepsize] = wibbledmean(squareaccum)\n",
    "\n",
    "    def filldiamonds():\n",
    "        \"\"\"For each diamond of points stepsize apart,\n",
    "           calculate middle value as mean of points + wibble\"\"\"\n",
    "        mapsize = maparray.shape[0]\n",
    "        drgrid = maparray[stepsize // 2:mapsize:stepsize, stepsize // 2:mapsize:stepsize]\n",
    "        ulgrid = maparray[0:mapsize:stepsize, 0:mapsize:stepsize]\n",
    "        ldrsum = drgrid + np.roll(drgrid, 1, axis=0)\n",
    "        lulsum = ulgrid + np.roll(ulgrid, -1, axis=1)\n",
    "        ltsum = ldrsum + lulsum\n",
    "        maparray[0:mapsize:stepsize, stepsize // 2:mapsize:stepsize] = wibbledmean(ltsum)\n",
    "        tdrsum = drgrid + np.roll(drgrid, 1, axis=1)\n",
    "        tulsum = ulgrid + np.roll(ulgrid, -1, axis=0)\n",
    "        ttsum = tdrsum + tulsum\n",
    "        maparray[stepsize // 2:mapsize:stepsize, 0:mapsize:stepsize] = wibbledmean(ttsum)\n",
    "\n",
    "    while stepsize >= 2:\n",
    "        fillsquares()\n",
    "        filldiamonds()\n",
    "        stepsize //= 2\n",
    "        wibble /= wibbledecay\n",
    "\n",
    "    maparray -= maparray.min()\n",
    "    return maparray / maparray.max()\n",
    "\n",
    "\n",
    "def clipped_zoom(img, zoom_factor):\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    # ceil crop height(= crop width)\n",
    "    ch = int(np.ceil(h / zoom_factor))\n",
    "    cw = int(np.ceil(w / zoom_factor))\n",
    "\n",
    "    toph = (h - ch) // 2\n",
    "    topw = (w - cw) // 2\n",
    "    img = scizoom(img[toph:toph + ch, topw:topw + cw], (zoom_factor, zoom_factor, 1), order=1)\n",
    "    # trim off any extra pixels\n",
    "    trim_toph = (img.shape[0] - h) // 2\n",
    "    trim_topw = (img.shape[1] - w) // 2\n",
    "\n",
    "    return img[trim_toph:trim_toph + h, trim_topw:trim_topw + w]\n",
    "\n",
    "\n",
    "# /////////////// End Distortion Helpers ///////////////\n",
    "\n",
    "\n",
    "# /////////////// Distortions ///////////////\n",
    "\n",
    "def gaussian_noise(x, severity=1):\n",
    "    c = [.08, .12, 0.18, 0.26, 0.38][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    return np.clip(x + np.random.normal(size=x.shape, scale=c), 0, 1) * 255\n",
    "\n",
    "def shot_noise(x, severity=1):\n",
    "    c = [60, 25, 12, 5, 3][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    return np.clip(np.random.poisson(x * c) / c, 0, 1) * 255\n",
    "\n",
    "\n",
    "def impulse_noise(x, severity=1):\n",
    "    c = [.03, .06, .09, 0.17, 0.27][severity - 1]\n",
    "\n",
    "    x = sk.util.random_noise(np.array(x) / 255., mode='s&p', amount=c)\n",
    "    return np.clip(x, 0, 1) * 255\n",
    "\n",
    "\n",
    "def speckle_noise(x, severity=1):\n",
    "    c = [.15, .2, 0.35, 0.45, 0.6][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    return np.clip(x + x * np.random.normal(size=x.shape, scale=c), 0, 1) * 255\n",
    "\n",
    "\n",
    "def fgsm(x, source_net, severity=1):\n",
    "    c = [8, 16, 32, 64, 128][severity - 1]\n",
    "\n",
    "    x = V(x, requires_grad=True)\n",
    "    logits = source_net(x)\n",
    "    source_net.zero_grad()\n",
    "    loss = F.cross_entropy(logits, V(logits.data.max(1)[1].squeeze_()), size_average=False)\n",
    "    loss.backward()\n",
    "\n",
    "    return standardize(torch.clamp(unstandardize(x.data) + c / 255. * unstandardize(torch.sign(x.grad.data)), 0, 1))\n",
    "\n",
    "\n",
    "def gaussian_blur(x, severity=1):\n",
    "    c = [1, 2, 3, 4, 6][severity - 1]\n",
    "\n",
    "    x = gaussian(np.array(x) / 255., sigma=c, multichannel=True)\n",
    "    return np.clip(x, 0, 1) * 255\n",
    "\n",
    "\n",
    "def glass_blur(x, severity=1):\n",
    "    \n",
    "    x_h = np.array(x).shape[0]\n",
    "    x_w = np.array(x).shape[1]\n",
    "    \n",
    "    # sigma, max_delta, iterations\n",
    "    c = [(0.7, 1, 2), (0.9, 2, 1), (1, 2, 3), (1.1, 3, 2), (1.5, 4, 2)][severity - 1]\n",
    "\n",
    "    x = np.uint8(gaussian(np.array(x) / 255., sigma=c[0], multichannel=True) * 255)\n",
    "\n",
    "    # locally shuffle pixels\n",
    "    for i in range(c[2]):\n",
    "        for h in range(x_h - c[1], c[1], -1):\n",
    "            for w in range(x_w - c[1], c[1], -1):\n",
    "                dx, dy = np.random.randint(-c[1], c[1], size=(2,))\n",
    "                h_prime, w_prime = h + dy, w + dx\n",
    "                # swap\n",
    "                x[h, w], x[h_prime, w_prime] = x[h_prime, w_prime], x[h, w]\n",
    "\n",
    "    return np.clip(gaussian(x / 255., sigma=c[0], multichannel=True), 0, 1) * 255\n",
    "\n",
    "\n",
    "def defocus_blur(x, severity=1):\n",
    "    c = [(3, 0.1), (4, 0.5), (6, 0.5), (8, 0.5), (10, 0.5)][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    kernel = disk(radius=c[0], alias_blur=c[1])\n",
    "\n",
    "    channels = []\n",
    "    for d in range(3):\n",
    "        channels.append(cv2.filter2D(x[:, :, d], -1, kernel))\n",
    "    channels = np.array(channels).transpose((1, 2, 0))  # 3x224x224 -> 224x224x3\n",
    "\n",
    "    return np.clip(channels, 0, 1) * 255\n",
    "\n",
    "\n",
    "def motion_blur(x, severity=1):\n",
    "    \n",
    "    x_h = np.array(x).shape[0]\n",
    "    x_w = np.array(x).shape[1]\n",
    "    \n",
    "    c = [(10, 3), (15, 5), (15, 8), (15, 12), (20, 15)][severity - 1]\n",
    "\n",
    "    output = BytesIO()\n",
    "    x.save(output, format='PNG')\n",
    "    x = MotionImage(blob=output.getvalue())\n",
    "\n",
    "    x.motion_blur(radius=c[0], sigma=c[1], angle=np.random.uniform(-45, 45))\n",
    "\n",
    "    x = cv2.imdecode(np.fromstring(x.make_blob(), np.uint8),\n",
    "                     cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    if x.shape != (x_h, x_w):\n",
    "        return np.clip(x[..., [2, 1, 0]], 0, 255)  # BGR to RGB\n",
    "    else:  # greyscale to RGB\n",
    "        return np.clip(np.array([x, x, x]).transpose((1, 2, 0)), 0, 255)\n",
    "\n",
    "\n",
    "def zoom_blur(x, severity=1):\n",
    "    c = [np.arange(1, 1.11, 0.01),\n",
    "         np.arange(1, 1.16, 0.01),\n",
    "         np.arange(1, 1.21, 0.02),\n",
    "         np.arange(1, 1.26, 0.02),\n",
    "         np.arange(1, 1.31, 0.03)][severity - 1]\n",
    "\n",
    "    x = (np.array(x) / 255.).astype(np.float32)\n",
    "    out = np.zeros_like(x)\n",
    "    for zoom_factor in c:\n",
    "        out += clipped_zoom(x, zoom_factor)\n",
    "\n",
    "    x = (x + out) / (len(c) + 1)\n",
    "    return np.clip(x, 0, 1) * 255\n",
    "\n",
    "\n",
    "def fog(x, severity=1):\n",
    "    \n",
    "    x_h = np.array(x).shape[0]\n",
    "    x_w = np.array(x).shape[1]\n",
    "    \n",
    "    c = [(1.5, 2), (2, 2), (2.5, 1.7), (2.5, 1.5), (3, 1.4)][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    max_val = x.max()\n",
    "    x += c[0] * plasma_fractal(mapsize = 1024, wibbledecay=c[1])[:x_h, :x_w][..., np.newaxis]\n",
    "    return np.clip(x * max_val / (max_val + c[0]), 0, 1) * 255\n",
    "\n",
    "\n",
    "def frost(x, severity=1):\n",
    "    \n",
    "    x_h = np.array(x).shape[0]\n",
    "    x_w = np.array(x).shape[1]\n",
    "    \n",
    "    c = [(1, 0.4),\n",
    "         (0.8, 0.6),\n",
    "         (0.7, 0.7),\n",
    "         (0.65, 0.7),\n",
    "         (0.6, 0.75)][severity - 1]\n",
    "    idx = np.random.randint(5)\n",
    "    filename = ['./frost/frost1.png', './frost/frost2.png', './frost/frost3.png', './frost/frost4.jpg', './frost/frost5.jpg', './frost6.jpg'][idx]\n",
    "    frost = cv2.imread(filename)\n",
    "    frost = cv2.resize(frost, (x_w, x_h))\n",
    "    # randomly crop and convert to rgb\n",
    "    x_start, y_start = np.random.randint(0, frost.shape[0] - x_h + 1), np.random.randint(0, frost.shape[1] - x_w + 1)\n",
    "    frost = frost[x_start:x_start + x_h, y_start:y_start + x_w][..., [2, 1, 0]]\n",
    "\n",
    "    return np.clip(c[0] * np.array(x) + c[1] * frost, 0, 255)\n",
    "\n",
    "\n",
    "def snow(x, severity=1):\n",
    "    \n",
    "    x_h = np.array(x).shape[0]\n",
    "    x_w = np.array(x).shape[1]\n",
    "    \n",
    "    c = [(0.1, 0.3, 3, 0.5, 10, 4, 0.8),\n",
    "         (0.2, 0.3, 2, 0.5, 12, 4, 0.7),\n",
    "         (0.55, 0.3, 4, 0.9, 12, 8, 0.7),\n",
    "         (0.55, 0.3, 4.5, 0.85, 12, 8, 0.65),\n",
    "         (0.55, 0.3, 2.5, 0.85, 12, 12, 0.55)][severity - 1]\n",
    "\n",
    "    x = np.array(x, dtype=np.float32) / 255.\n",
    "    snow_layer = np.random.normal(size=x.shape[:2], loc=c[0], scale=c[1])  # [:2] for monochrome\n",
    "\n",
    "    snow_layer = clipped_zoom(snow_layer[..., np.newaxis], c[2])\n",
    "    snow_layer[snow_layer < c[3]] = 0\n",
    "\n",
    "    snow_layer = PILImage.fromarray((np.clip(snow_layer.squeeze(), 0, 1) * 255).astype(np.uint8), mode='L')\n",
    "    output = BytesIO()\n",
    "    snow_layer.save(output, format='PNG')\n",
    "    snow_layer = MotionImage(blob=output.getvalue())\n",
    "\n",
    "    snow_layer.motion_blur(radius=c[4], sigma=c[5], angle=np.random.uniform(-135, -45))\n",
    "\n",
    "    snow_layer = cv2.imdecode(np.fromstring(snow_layer.make_blob(), np.uint8),\n",
    "                              cv2.IMREAD_UNCHANGED) / 255.\n",
    "    snow_layer = snow_layer[..., np.newaxis]\n",
    "\n",
    "    x = c[6] * x + (1 - c[6]) * np.maximum(x, cv2.cvtColor(x, cv2.COLOR_RGB2GRAY).reshape(x_h, x_w, 1) * 1.5 + 0.5)\n",
    "    return np.clip(x + snow_layer + np.rot90(snow_layer, k=2), 0, 1) * 255\n",
    "\n",
    "\n",
    "def spatter(x, severity=1):\n",
    "    c = [(0.65, 0.3, 4, 0.69, 0.6, 0),\n",
    "         (0.65, 0.3, 3, 0.68, 0.6, 0),\n",
    "         (0.65, 0.3, 2, 0.68, 0.5, 0),\n",
    "         (0.65, 0.3, 1, 0.65, 1.5, 1),\n",
    "         (0.67, 0.4, 1, 0.65, 1.5, 1)][severity - 1]\n",
    "    x = np.array(x, dtype=np.float32) / 255.\n",
    "\n",
    "    liquid_layer = np.random.normal(size=x.shape[:2], loc=c[0], scale=c[1])\n",
    "\n",
    "    liquid_layer = gaussian(liquid_layer, sigma=c[2])\n",
    "    liquid_layer[liquid_layer < c[3]] = 0\n",
    "    if c[5] == 0:\n",
    "        liquid_layer = (liquid_layer * 255).astype(np.uint8)\n",
    "        dist = 255 - cv2.Canny(liquid_layer, 50, 150)\n",
    "        dist = cv2.distanceTransform(dist, cv2.DIST_L2, 5)\n",
    "        _, dist = cv2.threshold(dist, 20, 20, cv2.THRESH_TRUNC)\n",
    "        dist = cv2.blur(dist, (3, 3)).astype(np.uint8)\n",
    "        dist = cv2.equalizeHist(dist)\n",
    "        #     ker = np.array([[-1,-2,-3],[-2,0,0],[-3,0,1]], dtype=np.float32)\n",
    "        #     ker -= np.mean(ker)\n",
    "        ker = np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])\n",
    "        dist = cv2.filter2D(dist, cv2.CV_8U, ker)\n",
    "        dist = cv2.blur(dist, (3, 3)).astype(np.float32)\n",
    "\n",
    "        m = cv2.cvtColor(liquid_layer * dist, cv2.COLOR_GRAY2BGRA)\n",
    "        m /= np.max(m, axis=(0, 1))\n",
    "        m *= c[4]\n",
    "\n",
    "        # water is pale turqouise\n",
    "        color = np.concatenate((175 / 255. * np.ones_like(m[..., :1]),\n",
    "                                238 / 255. * np.ones_like(m[..., :1]),\n",
    "                                238 / 255. * np.ones_like(m[..., :1])), axis=2)\n",
    "\n",
    "        color = cv2.cvtColor(color, cv2.COLOR_BGR2BGRA)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "        return cv2.cvtColor(np.clip(x + m * color, 0, 1), cv2.COLOR_BGRA2BGR) * 255\n",
    "    else:\n",
    "        m = np.where(liquid_layer > c[3], 1, 0)\n",
    "        m = gaussian(m.astype(np.float32), sigma=c[4])\n",
    "        m[m < 0.8] = 0\n",
    "        #         m = np.abs(m) ** (1/c[4])\n",
    "\n",
    "        # mud brown\n",
    "        color = np.concatenate((63 / 255. * np.ones_like(x[..., :1]),\n",
    "                                42 / 255. * np.ones_like(x[..., :1]),\n",
    "                                20 / 255. * np.ones_like(x[..., :1])), axis=2)\n",
    "\n",
    "        color *= m[..., np.newaxis]\n",
    "        x *= (1 - m[..., np.newaxis])\n",
    "\n",
    "        return np.clip(x + color, 0, 1) * 255\n",
    "\n",
    "\n",
    "def contrast(x, severity=1):\n",
    "    c = [0.4, .3, .2, .1, .05][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    means = np.mean(x, axis=(0, 1), keepdims=True)\n",
    "    return np.clip((x - means) * c + means, 0, 1) * 255\n",
    "\n",
    "\n",
    "def brightness(x, severity=1):\n",
    "    c = [.1, .2, .3, .4, .5][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    x = sk.color.rgb2hsv(x)\n",
    "    x[:, :, 2] = np.clip(x[:, :, 2] + c, 0, 1)\n",
    "    x = sk.color.hsv2rgb(x)\n",
    "\n",
    "    return np.clip(x, 0, 1) * 255\n",
    "\n",
    "\n",
    "def saturate(x, severity=1):\n",
    "    c = [(0.3, 0), (0.1, 0), (2, 0), (5, 0.1), (20, 0.2)][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    x = sk.color.rgb2hsv(x)\n",
    "    x[:, :, 1] = np.clip(x[:, :, 1] * c[0] + c[1], 0, 1)\n",
    "    x = sk.color.hsv2rgb(x)\n",
    "\n",
    "    return np.clip(x, 0, 1) * 255\n",
    "\n",
    "\n",
    "def jpeg_compression(x, severity=1):\n",
    "    c = [25, 18, 15, 10, 7][severity - 1]\n",
    "\n",
    "    output = BytesIO()\n",
    "    x.save(output, 'JPEG', quality=c)\n",
    "    x = PILImage.open(output)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def pixelate(x, severity=1):\n",
    "    \n",
    "    x_h = np.array(x).shape[0]\n",
    "    x_w = np.array(x).shape[1]\n",
    "    \n",
    "    c = [0.6, 0.5, 0.4, 0.3, 0.25][severity - 1]\n",
    "\n",
    "    x = x.resize((int(x_h * c), int(x_w * c)), PILImage.BOX)\n",
    "    x = x.resize((x_h, x_w), PILImage.BOX)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# mod of https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
    "def elastic_transform(image, severity=1):\n",
    "    c = [(244 * 2, 244 * 0.7, 244 * 0.1),   # 244 should have been 224, but ultimately nothing is incorrect\n",
    "         (244 * 2, 244 * 0.08, 244 * 0.2),\n",
    "         (244 * 0.05, 244 * 0.01, 244 * 0.02),\n",
    "         (244 * 0.07, 244 * 0.01, 244 * 0.02),\n",
    "         (244 * 0.12, 244 * 0.01, 244 * 0.02)][severity - 1]\n",
    "\n",
    "    image = np.array(image, dtype=np.float32) / 255.\n",
    "    shape = image.shape\n",
    "    shape_size = shape[:2]\n",
    "\n",
    "    # random affine\n",
    "    center_square = np.float32(shape_size) // 2\n",
    "    square_size = min(shape_size) // 3\n",
    "    pts1 = np.float32([center_square + square_size,\n",
    "                       [center_square[0] + square_size, center_square[1] - square_size],\n",
    "                       center_square - square_size])\n",
    "    pts2 = pts1 + np.random.uniform(-c[2], c[2], size=pts1.shape).astype(np.float32)\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    dx = (gaussian(np.random.uniform(-1, 1, size=shape[:2]),\n",
    "                   c[1], mode='reflect', truncate=3) * c[0]).astype(np.float32)\n",
    "    dy = (gaussian(np.random.uniform(-1, 1, size=shape[:2]),\n",
    "                   c[1], mode='reflect', truncate=3) * c[0]).astype(np.float32)\n",
    "    dx, dy = dx[..., np.newaxis], dy[..., np.newaxis]\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
    "    indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "    return np.clip(map_coordinates(image, indices, order=1, mode='reflect').reshape(shape), 0, 1) * 255\n",
    "\n",
    "\n",
    "# /////////////// End Distortions ///////////////\n",
    "\n",
    "\n",
    "# /////////////// Further Setup ///////////////\n",
    "\n",
    "\n",
    "def save_distorted(method=gaussian_noise):\n",
    "    for severity in range(1, 6):\n",
    "        print(method.__name__, severity)\n",
    "        distorted_dataset = DistortImageFolder(\n",
    "            root=HAMtestfolder,\n",
    "            method=method, severity=severity)\n",
    "        distorted_dataset_loader = torch.utils.data.DataLoader(\n",
    "            distorted_dataset, batch_size=100, shuffle=False, num_workers=1)\n",
    "        # note that, num_workers might need to be set to 1, to avoid the duplicated error of os.makedirs\n",
    "\n",
    "        for _ in distorted_dataset_loader: continue\n",
    "\n",
    "\n",
    "# /////////////// End Further Setup ///////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using HAM test data\n",
      "contrast 1\n",
      "contrast 2\n",
      "contrast 3\n",
      "contrast 4\n",
      "contrast 5\n",
      "elastic_transform 1\n",
      "elastic_transform 2\n",
      "elastic_transform 3\n",
      "elastic_transform 4\n",
      "elastic_transform 5\n",
      "pixelate 1\n",
      "pixelate 2\n",
      "pixelate 3\n",
      "pixelate 4\n",
      "pixelate 5\n",
      "jpeg_compression 1\n",
      "jpeg_compression 2\n",
      "jpeg_compression 3\n",
      "jpeg_compression 4\n",
      "jpeg_compression 5\n",
      "speckle_noise 1\n",
      "speckle_noise 2\n",
      "speckle_noise 3\n",
      "speckle_noise 4\n",
      "speckle_noise 5\n",
      "gaussian_blur 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-32263731/ipykernel_85535/3899939079.py:267: FutureWarning: `multichannel` is a deprecated argument name for `gaussian`. It will be removed in version 1.0.Please use `channel_axis` instead.\n",
      "  x = gaussian(np.array(x) / 255., sigma=c, multichannel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_blur 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-32263731/ipykernel_85535/3899939079.py:267: FutureWarning: `multichannel` is a deprecated argument name for `gaussian`. It will be removed in version 1.0.Please use `channel_axis` instead.\n",
      "  x = gaussian(np.array(x) / 255., sigma=c, multichannel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_blur 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-32263731/ipykernel_85535/3899939079.py:267: FutureWarning: `multichannel` is a deprecated argument name for `gaussian`. It will be removed in version 1.0.Please use `channel_axis` instead.\n",
      "  x = gaussian(np.array(x) / 255., sigma=c, multichannel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_blur 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-32263731/ipykernel_85535/3899939079.py:267: FutureWarning: `multichannel` is a deprecated argument name for `gaussian`. It will be removed in version 1.0.Please use `channel_axis` instead.\n",
      "  x = gaussian(np.array(x) / 255., sigma=c, multichannel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_blur 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-32263731/ipykernel_85535/3899939079.py:267: FutureWarning: `multichannel` is a deprecated argument name for `gaussian`. It will be removed in version 1.0.Please use `channel_axis` instead.\n",
      "  x = gaussian(np.array(x) / 255., sigma=c, multichannel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatter 1\n",
      "spatter 2\n",
      "spatter 3\n",
      "spatter 4\n",
      "spatter 5\n",
      "saturate 1\n",
      "saturate 2\n",
      "saturate 3\n",
      "saturate 4\n",
      "saturate 5\n"
     ]
    }
   ],
   "source": [
    "# /////////////// Display Results ///////////////\n",
    "import collections\n",
    "\n",
    "print('\\nUsing HAM test data')\n",
    "\n",
    "d = collections.OrderedDict()\n",
    "d['Gaussian Noise'] = gaussian_noise\n",
    "d['Shot Noise'] = shot_noise\n",
    "d['Impulse Noise'] = impulse_noise\n",
    "d['Defocus Blur'] = defocus_blur\n",
    "d['Glass Blur'] = glass_blur\n",
    "d['Motion Blur'] = motion_blur\n",
    "d['Zoom Blur'] = zoom_blur\n",
    "# d['Snow'] = snow\n",
    "d['Frost'] = frost\n",
    "d['Fog'] = fog\n",
    "d['Brightness'] = brightness\n",
    "d['Contrast'] = contrast\n",
    "d['Elastic'] = elastic_transform\n",
    "d['Pixelate'] = pixelate\n",
    "d['JPEG'] = jpeg_compression\n",
    "\n",
    "d['Speckle Noise'] = speckle_noise\n",
    "d['Gaussian Blur'] = gaussian_blur\n",
    "d['Spatter'] = spatter\n",
    "d['Saturate'] = saturate\n",
    "\n",
    "for method_name in d.keys():\n",
    "    save_distorted(d[method_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skinclassifier",
   "language": "python",
   "name": "skinclassifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
